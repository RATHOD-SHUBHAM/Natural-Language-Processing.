# -*- coding: utf-8 -*-
"""ChatBot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nY5u0bStR3AD17ALbGFY_3cMPc5gadWT

## Import **Library**
"""

import numpy as np
import nltk
import string
import random

"""## Upload a file to colab"""

# once you are done just comment it out
# from google.colab import files
# uploaded = files.upload()

"""# Reading the **Corpus**"""

f = open('chatbot.txt','r',errors='ignore')
raw_docs = f.read() # read the content from file handler
raw_docs = raw_docs.lower() # convert everything into lower case

# tokenization
nltk.download('punkt')
nltk.download('wordnet')

sent_tokens = nltk.sent_tokenize(raw_docs) # convert entire file into sentence
word_tokens = nltk.word_tokenize(raw_docs) # convert sentences into list of words

sent_tokens[:2]

word_tokens[:5]

"""# Text Preprocessing """

# lemmatization
lemmer = nltk.stem.WordNetLemmatizer()

def lemToken(tokens):
  return [lemmer.lemmatize(token) for token in tokens]

# remove punctuations
remove_punc = dict((ord(punc),None) for punc in string.punctuation)

def lemNormalize(text):
  return lemToken(nltk.word_tokenize(text.lower().translate(remove_punc)))

"""# Greeting Function"""

greet = ("Hello","Hey","Hi","hi","hiii","Hiii","Wasup","Whats up","Hey, How you doing?","sup","supppp")
greet_responce = ["Hello", "Hey","Hi","Hi, am good. how about you","hmm listening"]


def greeting(sentence):
  for word in sentence.split():
    if word.lower() in greet:
      return random.choice(greet_responce) # gives a random greeting

"""# Response Generation
### **TFIDF**
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def respose(user_response):
  respose = ''
  tfidf_Vec = TfidfVectorizer(tokenizer=lemNormalize, stop_words='english')
  tfidf = tfidf_Vec.fit_transform(sent_tokens)
  # print(tfidf)
  vals = cosine_similarity(tfidf[-1],tfidf)
  idx = vals.argsort()[0][-2]
  flat = vals.flatten()
  flat.sort()
  req_tfidf = flat[-2]
  if (req_tfidf == 0):
    respose = respose + 'Sorry, I quite didnt get you'
    return respose
  else:
    respose = respose + sent_tokens[idx]
    return respose

"""# Defining Start and End Protocol"""

flag = True
print("Bot: Hello, How can I help you? , If you want to exit at any time, Just say Bye :c ")
while flag == True:
  user_respose = input()
  user_respose = user_respose.lower()
  if user_respose != 'bye':
    if user_respose == 'thank you' or user_respose == 'thanks':
      flag = False
      print("Bot: Pleasure was mine")
    else:
      if greeting(user_respose) != None :
        print("Bot: "+greeting(user_respose))
      else:
        sent_tokens.append(user_respose)
        word_tokens = word_tokens+nltk.word_tokenize(user_respose)
        final_words = list(set(word_tokens))

        print("Bot: ",end = '')
        print(respose(user_respose))
        
        sent_tokens.remove(user_respose)

  else:
    flag = False
    print("Bot: Bye. see you soon <3 ")